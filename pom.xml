<?xml version="1.0" encoding="UTF-8"?>
<!-- ~ Licensed to the Apache Software Foundation (ASF) under one or more 
	~ contributor license agreements. See the NOTICE file distributed with ~ 
	this work for additional information regarding copyright ownership. ~ The 
	ASF licenses this file to You under the Apache License, Version 2.0 ~ (the 
	"License"); you may not use this file except in compliance with ~ the License. 
	You may obtain a copy of the License at ~ ~ http://www.apache.org/licenses/LICENSE-2.0 
	~ ~ Unless required by applicable law or agreed to in writing, software ~ 
	distributed under the License is distributed on an "AS IS" BASIS, ~ WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. ~ See the 
	License for the specific language governing permissions and ~ limitations 
	under the License. -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.qiwur.athena</groupId>
	<artifactId>athena</artifactId>
	<version>0.9.0</version>

	<packaging>pom</packaging>
	<name>Qiwur Athena Parent POM</name>
	<url>http://athena.qiwur.org/</url>

	<licenses>
		<license>
			<name>Apache 2.0 License</name>
			<url>http://www.apache.org/licenses/LICENSE-2.0.html</url>
			<distribution>repo</distribution>
		</license>
	</licenses>

	<prerequisites>
		<maven>3.0.4</maven>
	</prerequisites>

	<modules>
		<module>examples</module>
	</modules>

	<properties>
		<!-- Data Platform Dependencies -->
		<hadoop.version>2.5.2</hadoop.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<hbase.version>0.98.8-hadoop2</hbase.version>
		<spark.version>1.4.1</spark.version>

		<!-- Misc Dependencies -->
		<guava.version>11.0.2</guava.version>
		<commons-lang.version>2.6</commons-lang.version>

		<!-- Logging And Testing Dependencies -->
		<log4j.version>1.2.16</log4j.version>
		<slf4j.version>1.7.5</slf4j.version>
		<junit.version>4.10</junit.version>
		<perf4j.version>0.9.16</perf4j.version>

		<!-- General Properties -->
		<java.version>1.7</java.version>
		<javac.src.version>1.7</javac.src.version>
		<javac.target.version>1.7</javac.target.version>
		<scala.macros.version>2.0.1</scala.macros.version>
		<scala.version>2.10.4</scala.version>
		<scala.binary.version>2.10</scala.binary.version>

		<implementation.build>${scmBranch}@r${buildNumber}</implementation.build>
		<maven.build.timestamp.format>yyyy-MM-dd HH:mm:ssZ</maven.build.timestamp.format>
		<skipTests>true</skipTests>
		<assembly.finalName>qiwur-${project.build.finalName}</assembly.finalName>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>

		<PermGen>64m</PermGen>
		<MaxPermGen>512m</MaxPermGen>
		<CodeCacheSize>512m</CodeCacheSize>
	</properties>

	<pluginRepositories>
		<pluginRepository>
			<id>central</id>
			<url>https://repo1.maven.org/maven2</url>
			<releases>
				<enabled>true</enabled>
			</releases>
			<snapshots>
				<enabled>false</enabled>
			</snapshots>
		</pluginRepository>
	</pluginRepositories>

	<dependencyManagement>
		<dependencies>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-core_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-core_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-streaming_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-mllib_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-bagel_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-hive_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
			<dependency>
				<groupId>org.apache.spark</groupId>
				<artifactId>spark-graphx_2.10</artifactId>
				<version>${spark.version}</version>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<defaultGoal>install</defaultGoal>
		<directory>target</directory>
		<finalName>${project.artifactId}-${project.version}</finalName>

		<sourceDirectory>${basedir}/src/main/java</sourceDirectory>
		<outputDirectory>${basedir}/target/classes</outputDirectory>

		<testSourceDirectory>${basedir}/src/test/java</testSourceDirectory>
		<testOutputDirectory>${basedir}/target/test-classes</testOutputDirectory>

		<resources>
			<resource>
				<directory>${basedir}/src/main/resources</directory>
			</resource>
		</resources>
		<testResources>
			<testResource>
				<directory>${basedir}/src/test/resources</directory>
			</testResource>
		</testResources>

		<pluginManagement>
			<plugins>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-enforcer-plugin</artifactId>
					<version>1.4</version>
					<executions>
						<execution>
							<id>enforce-versions</id>
							<goals>
								<goal>enforce</goal>
							</goals>
							<configuration>
								<rules>
									<requireMavenVersion>
										<version>3.0.4</version>
									</requireMavenVersion>
									<requireJavaVersion>
										<version>${java.version}</version>
									</requireJavaVersion>
								</rules>
							</configuration>
						</execution>
					</executions>
				</plugin>
				<plugin>
					<groupId>org.codehaus.mojo</groupId>
					<artifactId>build-helper-maven-plugin</artifactId>
					<version>1.9.1</version>
				</plugin>
				<plugin>
					<groupId>net.alchim31.maven</groupId>
					<artifactId>scala-maven-plugin</artifactId>
					<version>3.2.0</version>
					<executions>
						<execution>
							<id>eclipse-add-source</id>
							<goals>
								<goal>add-source</goal>
							</goals>
						</execution>
						<execution>
							<id>scala-compile-first</id>
							<phase>process-resources</phase>
							<goals>
								<goal>compile</goal>
							</goals>
						</execution>
						<execution>
							<id>scala-test-compile-first</id>
							<phase>process-test-resources</phase>
							<goals>
								<goal>testCompile</goal>
							</goals>
						</execution>
						<execution>
							<id>attach-scaladocs</id>
							<phase>verify</phase>
							<goals>
								<goal>doc-jar</goal>
							</goals>
						</execution>
					</executions>
					<configuration>
						<scalaVersion>${scala.version}</scalaVersion>
						<recompileMode>incremental</recompileMode>
						<useZincServer>true</useZincServer>
						<args>
							<arg>-unchecked</arg>
							<arg>-deprecation</arg>
							<arg>-feature</arg>
						</args>
						<jvmArgs>
							<jvmArg>-Xms1024m</jvmArg>
							<jvmArg>-Xmx1024m</jvmArg>
							<jvmArg>-XX:PermSize=${PermGen}</jvmArg>
							<jvmArg>-XX:MaxPermSize=${MaxPermGen}</jvmArg>
							<jvmArg>-XX:ReservedCodeCacheSize=${CodeCacheSize}</jvmArg>
						</jvmArgs>
						<javacArgs>
							<javacArg>-source</javacArg>
							<javacArg>${java.version}</javacArg>
							<javacArg>-target</javacArg>
							<javacArg>${java.version}</javacArg>
						</javacArgs>
						<!-- The following plugin is required to use quasiquotes in Scala 2.10 
							and is used by Spark SQL for code generation. -->
						<compilerPlugins>
							<compilerPlugin>
								<groupId>org.scalamacros</groupId>
								<artifactId>paradise_${scala.version}</artifactId>
								<version>${scala.macros.version}</version>
							</compilerPlugin>
						</compilerPlugins>
					</configuration>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>3.3</version>
					<configuration>
						<source>${java.version}</source>
						<target>${java.version}</target>
						<encoding>UTF-8</encoding>
						<maxmem>1024m</maxmem>
						<fork>true</fork>
					</configuration>
				</plugin>
				<!-- Surefire runs all Java tests -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-surefire-plugin</artifactId>
					<version>2.18.1</version>
					<!-- Note config is repeated in scalatest config -->
					<configuration>
						<includes>
							<include>**/Test*.java</include>
							<include>**/*Test.java</include>
							<include>**/*TestCase.java</include>
							<include>**/*Suite.java</include>
						</includes>
						<reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
						<argLine>-Xmx3g -Xss4096k -XX:MaxPermSize=${MaxPermGen}
							-XX:ReservedCodeCacheSize=512m</argLine>
						<environmentVariables>
							<!-- Setting SPARK_DIST_CLASSPATH is a simple way to make sure any 
								child processes launched by the tests have access to the correct test-time 
								classpath. -->
							<SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>
							<JAVA_HOME>${test.java.home}</JAVA_HOME>
						</environmentVariables>
						<systemProperties>
							<java.awt.headless>true</java.awt.headless>
							<java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
							<spark.test.home>${spark.test.home}</spark.test.home>
							<spark.testing>1</spark.testing>
							<spark.ui.enabled>false</spark.ui.enabled>
							<spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
							<spark.driver.allowMultipleContexts>true</spark.driver.allowMultipleContexts>
							<spark.unsafe.exceptionOnMemoryLeak>true</spark.unsafe.exceptionOnMemoryLeak>
						</systemProperties>
						<failIfNoTests>false</failIfNoTests>
					</configuration>
				</plugin>
				<!-- Scalatest runs all Scala tests -->
				<plugin>
					<groupId>org.scalatest</groupId>
					<artifactId>scalatest-maven-plugin</artifactId>
					<version>1.0</version>
					<!-- Note config is repeated in surefire config -->
					<configuration>
						<reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
						<junitxml>.</junitxml>
						<filereports>SparkTestSuite.txt</filereports>
						<argLine>-ea -Xmx3g -XX:MaxPermSize=${MaxPermGen}
							-XX:ReservedCodeCacheSize=${CodeCacheSize}</argLine>
						<stderr />
						<environmentVariables>
							<!-- Setting SPARK_DIST_CLASSPATH is a simple way to make sure any 
								child processes launched by the tests have access to the correct test-time 
								classpath. -->
							<SPARK_DIST_CLASSPATH>${test_classpath}</SPARK_DIST_CLASSPATH>
							<JAVA_HOME>${test.java.home}</JAVA_HOME>
						</environmentVariables>
						<systemProperties>
							<java.awt.headless>true</java.awt.headless>
							<java.io.tmpdir>${project.build.directory}/tmp</java.io.tmpdir>
							<spark.test.home>${spark.test.home}</spark.test.home>
							<spark.testing>1</spark.testing>
							<spark.ui.enabled>false</spark.ui.enabled>
							<spark.ui.showConsoleProgress>false</spark.ui.showConsoleProgress>
							<spark.driver.allowMultipleContexts>true</spark.driver.allowMultipleContexts>
						</systemProperties>
					</configuration>
					<executions>
						<execution>
							<id>test</id>
							<goals>
								<goal>test</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-jar-plugin</artifactId>
					<version>2.6</version>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-antrun-plugin</artifactId>
					<version>1.8</version>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-source-plugin</artifactId>
					<version>2.4</version>
					<configuration>
						<attach>true</attach>
					</configuration>
					<executions>
						<execution>
							<id>create-source-jar</id>
							<goals>
								<goal>jar-no-fork</goal>
								<goal>test-jar-no-fork</goal>
							</goals>
						</execution>
					</executions>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-clean-plugin</artifactId>
					<version>2.6.1</version>
					<configuration>
						<filesets>
							<fileset>
								<directory>work</directory>
							</fileset>
							<fileset>
								<directory>checkpoint</directory>
							</fileset>
							<fileset>
								<directory>lib_managed</directory>
							</fileset>
						</filesets>
					</configuration>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-javadoc-plugin</artifactId>
					<version>2.10.3</version>
				</plugin>
				<plugin>
					<groupId>org.codehaus.mojo</groupId>
					<artifactId>exec-maven-plugin</artifactId>
					<version>1.4.0</version>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-assembly-plugin</artifactId>
					<version>2.5.3</version>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-install-plugin</artifactId>
					<version>2.5.2</version>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-deploy-plugin</artifactId>
					<version>2.8.2</version>
				</plugin>


				<!-- This plugin dumps the test classpath into a file -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-dependency-plugin</artifactId>
					<version>2.10</version>
					<executions>
						<execution>
							<phase>test-compile</phase>
							<goals>
								<goal>build-classpath</goal>
							</goals>
							<configuration>
								<includeScope>test</includeScope>
								<outputFile>${test_classpath_file}</outputFile>
							</configuration>
						</execution>
					</executions>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-antrun-plugin</artifactId>
					<executions>
						<execution>
							<id>create-tmp-dir</id>
							<phase>generate-test-resources</phase>
							<goals>
								<goal>run</goal>
							</goals>
							<configuration>
								<target>
									<mkdir dir="${project.build.directory}/tmp" />
								</target>
							</configuration>
						</execution>
					</executions>
				</plugin>

			</plugins>
		</pluginManagement>

		<plugins>
			<!-- The shade plug-in is used here to create effective pom's (see SPARK-3812), 
				and also remove references from the shaded libraries from artifacts published 
				by Spark. -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>2.3</version>
				<configuration>
					<shadedArtifactAttached>false</shadedArtifactAttached>
					<!-- Work around MSHADE-148. See SPARK-8819. -->
					<createDependencyReducedPom>${create.dependency.reduced.pom}</createDependencyReducedPom>
					<artifactSet>
						<includes>
							<!-- At a minimum we must include this to force effective pom generation -->
							<include>org.spark-project.spark:unused</include>

							<include>org.eclipse.jetty:jetty-io</include>
							<include>org.eclipse.jetty:jetty-http</include>
							<include>org.eclipse.jetty:jetty-continuation</include>
							<include>org.eclipse.jetty:jetty-servlet</include>
							<include>org.eclipse.jetty:jetty-plus</include>
							<include>org.eclipse.jetty:jetty-security</include>
							<include>org.eclipse.jetty:jetty-util</include>
							<include>org.eclipse.jetty:jetty-server</include>
							<include>com.google.guava:guava</include>
						</includes>
					</artifactSet>
					<relocations>
						<relocation>
							<pattern>org.eclipse.jetty</pattern>
							<shadedPattern>org.spark-project.jetty</shadedPattern>
							<includes>
								<include>org.eclipse.jetty.**</include>
							</includes>
						</relocation>
						<relocation>
							<pattern>com.google.common</pattern>
							<shadedPattern>org.spark-project.guava</shadedPattern>
							<excludes>
								<!-- These classes cannot be relocated, because the Java API exposes 
									the "Optional" type; the others are referenced by the Optional class. -->
								<exclude>com/google/common/base/Absent*</exclude>
								<exclude>com/google/common/base/Function</exclude>
								<exclude>com/google/common/base/Optional*</exclude>
								<exclude>com/google/common/base/Present*</exclude>
								<exclude>com/google/common/base/Supplier</exclude>
							</excludes>
						</relocation>
					</relocations>
				</configuration>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-enforcer-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>build-helper-maven-plugin</artifactId>
				<executions>
					<execution>
						<id>add-scala-sources</id>
						<phase>generate-sources</phase>
						<goals>
							<goal>add-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/main/scala</source>
							</sources>
						</configuration>
					</execution>
					<execution>
						<id>add-scala-test-sources</id>
						<phase>generate-test-sources</phase>
						<goals>
							<goal>add-test-source</goal>
						</goals>
						<configuration>
							<sources>
								<source>src/test/scala</source>
							</sources>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-source-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>org.scalastyle</groupId>
				<artifactId>scalastyle-maven-plugin</artifactId>
				<version>0.7.0</version>
				<configuration>
					<verbose>false</verbose>
					<failOnViolation>true</failOnViolation>
					<includeTestSourceDirectory>false</includeTestSourceDirectory>
					<failOnWarning>false</failOnWarning>
					<sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
					<testSourceDirectory>${basedir}/src/test/scala</testSourceDirectory>
					<configLocation>scalastyle-config.xml</configLocation>
					<outputFile>${basedir}/target/scalastyle-output.xml</outputFile>
					<inputEncoding>${project.build.sourceEncoding}</inputEncoding>
					<outputEncoding>${project.reporting.outputEncoding}</outputEncoding>
				</configuration>
				<executions>
					<execution>
						<goals>
							<goal>check</goal>
						</goals>
					</execution>
				</executions>
			</plugin>

			<!-- Enable surefire and scalatest in all children, in one place: -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>org.scalatest</groupId>
				<artifactId>scalatest-maven-plugin</artifactId>
			</plugin>
			<!-- Build test-jar's for all projects, since some projects depend on 
				tests from others -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<executions>
					<execution>
						<id>prepare-test-jar</id>
						<phase>prepare-package</phase>
						<goals>
							<goal>test-jar</goal>
						</goals>
						<configuration>
							<excludes>
								<exclude>log4j.properties</exclude>
							</excludes>
						</configuration>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>

</project>
